"""
Loads applicant data from a JSON Lines file into a PostgreSQL database.

This module provides the `load_applicant_data` function, which connects to a
PostgreSQL database using a connection pool, creates an `applicants` table,
reads data from a specified JSON Lines file, and inserts the records.
It handles file I/O and database operations within secure context managers
(`with` statements) for proper resource management.

The script expects a `DATABASE_URL` environment variable to be set for
database connection and a valid path to a `.jsonl` file containing applicant
information.
"""
import os
import json
import psycopg_pool

def load_applicant_data(database_url: str, jsonl_file_path: str):
    """
    Loads applicant data from a JSON Lines file into a PostgreSQL database.

    Args:
        database_url: The connection string for the PostgreSQL database.
        jsonl_file_path: The path to the JSON Lines file containing applicant data.
    """
    # This is a constant, so the uppercase name is correct.
    # pylint: disable=C0103
    TABLE_NAME = "applicants"

    # Use a 'with' statement for the connection pool to ensure it's closed properly.
    with psycopg_pool.ConnectionPool(database_url, min_size=0, max_size=80) as pool:
        with pool.connection() as conn:
            with conn.cursor() as cur:
                # Drop table to create a new one in the next step
                cur.execute(f"DROP TABLE IF EXISTS {TABLE_NAME};")

                # Create applicants table
                cur.execute(f"""
                    CREATE TABLE {TABLE_NAME}(
                        p_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                        program TEXT,
                        comments TEXT,
                        date_added date,
                        url TEXT,
                        status TEXT,
                        term TEXT,
                        us_or_international TEXT,
                        gpa float,
                        gre float,
                        gre_v float,
                        gre_aw float,
                        degree TEXT,
                        llm_generated_program TEXT,
                        llm_generated_university TEXT
                    );""")
            conn.commit()  # Commit the table creation

            # Correctly read the JSON Lines file line by line to handle large files
            # and avoid the incorrect conversion to a single JSON object.
            data_to_insert = []
            with open(jsonl_file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    # Strip any trailing whitespace, including newlines.
                    line = line.strip()
                    if line:  # Ensure the line is not empty
                        try:
                            json_data = json.loads(line)
                            record = (
                                json_data.get('program'),
                                json_data.get('comments'),
                                json_data.get('date_added'),
                                json_data.get('url'),
                                json_data.get('status'),
                                json_data.get('term'),
                                json_data.get('US/International'),
                                json_data.get('GPA'),
                                json_data.get('GRE'),
                                json_data.get('GRE V'),
                                json_data.get('GRE AW'),
                                json_data.get('Degree'),
                                json_data.get('llm-generated-program'),
                                json_data.get('llm-generated-university')
                            )
                            data_to_insert.append(record)
                        except json.JSONDecodeError as e:
                            print(f"Skipping malformed JSON line: {e}")

            # Insert data in a single, efficient operation using `executemany`.
            if data_to_insert:
                with pool.connection() as conn:
                    with conn.cursor() as cur:
                        columns = [
                            'program', 'comments', 'date_added', 'url', 'status', 'term',
                            'us_or_international', 'gpa', 'gre', 'gre_v', 'gre_aw', 'degree',
                            'llm_generated_program', 'llm_generated_university'
                        ]
                        placeholders = ', '.join(['%s'] * len(columns))
                        insert_sql = (
                            f"INSERT INTO {TABLE_NAME} ({', '.join(columns)}) VALUES "
                            f"({placeholders})"
                        )
                        cur.executemany(insert_sql, data_to_insert)
                    conn.commit()
                print(f"Successfully inserted {len(data_to_insert)} records into {TABLE_NAME}.")
            else:
                print("No records found in the JSON Lines file to insert.")

    print("Script finished and pool closed.")

# The original script does not define how the function is called.
# Here is an example of how to execute the corrected code.
if __name__ == "__main__":
    DATABASE_URL = os.environ.get('DATABASE_URL')
    if not DATABASE_URL:
        raise ValueError("DATABASE_URL environment variable is not set.")

    # Correct path for jsonl file.
    JSONL_FILE_PATH = r'module_5\src\applicant_data.jsonl'

    # Check if the path exists before calling the function.
    if not os.path.exists(JSONL_FILE_PATH):
        raise FileNotFoundError(f"JSONL file not found at: {JSONL_FILE_PATH}")

    load_applicant_data(DATABASE_URL, JSONL_FILE_PATH)
