"""
Loads applicant data from the PostgreSQL database into a structured format for further analysis. 
Connects to the database using psycopg_pool and the environment variable DATABASE_URL.
Executes a query to fetch all applicant records.
Converts rows into JSON objects and saves them into module_3/applicant_data.json.jsonl.
"""
import os
import psycopg_pool
import json


# Create a connection pool with a min_size of 0 and a max_size of 80. 
# Use the 'DATABASE_URL' environment variable to connect to the database.
pool = psycopg_pool.ConnectionPool(os.environ['DATABASE_URL'], min_size= 0, max_size= 80)
jsonl_file_path = r'C:\Users\Shreya\jhu_software_concepts\module_2\applicant_data.json.jsonl'
table_name = 'applicants'

#Get a connection from the pool.
conn = pool.getconn()

with conn.cursor() as cur:

  # Drop table to create a new one in next step
  cur.execute(f"""
    DROP TABLE IF EXISTS {table_name};""")

  # Create applicants table
  cur.execute(f"""
    CREATE TABLE {table_name}(
      p_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      program TEXT,
      comments TEXT,
      date_added date,
      url TEXT,
      status TEXT,
      term TEXT,
      us_or_international TEXT,
      gpa float,
      gre float,
      gre_v float,
      gre_aw float,
      degree TEXT, 
      llm_generated_program TEXT,
      llm_generated_university TEXT
    );""")
  
  # Open json file with data
  with open(jsonl_file_path, 'r', encoding='utf-8') as f:
                # Read the entire file content
                file_content = f.read()
                # Wrap the content in a JSON array and parse it
                data_from_json = json.loads(f'[{file_content.replace("}\n{", "},{")}]')
  
  # Re-order data              
  data_from_json.reverse()
   
  # Empty list to populate        
  data_to_insert = []
  
  # Iterate through json and get respective fields
  for json_data in data_from_json:
    record = (          
        json_data.get('program'),
        json_data.get('comments'),
        json_data.get('date_added'),
        json_data.get('url'),
        json_data.get('status'),
        json_data.get('term'),
        json_data.get('US/International'),
        json_data.get('GPA'),
        json_data.get('GRE'),
        json_data.get('GRE V'),
        json_data.get('GRE AW'),
        json_data.get('Degree'),
        json_data.get('llm-generated-program'),
        json_data.get('llm-generated-university')
    )
    data_to_insert.append(record)

  # Insert data
  columns = [
      'program', 'comments', 'date_added', 'url', 'status', 'term',
      'us_or_international', 'gpa', 'gre', 'gre_v', 'gre_aw', 'degree', 
      'llm_generated_program', 'llm_generated_university'
  ]
  
  # Insert using executemany from 3rd version of psycopg
  cur.executemany(
    f"INSERT INTO {table_name} ({', '.join(columns)}) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)",
    data_to_insert
  )
  print(f"Successfully inserted {len(data_to_insert)} records into {table_name}")
  
  # Commit the changes to the database
  conn.commit()

# Close the connection
pool.putconn(conn)
conn.close()
print("Script finished and pool closed.")
